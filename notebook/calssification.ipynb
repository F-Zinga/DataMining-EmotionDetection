{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**CLASSIFICATION**\n",
    "\n",
    "In this notebook the goal is to use the data previously analyzed for training some classification model such as SVM, Random Forest and KNN, and try to predict if some comments contain a specified sentiment. So, we will have different binaries model. This choice is due to the low number of data and samples for each class.\n",
    "Let's import all the necessary packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, make_scorer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T17:41:39.387054Z",
     "end_time": "2023-04-07T17:41:39.406399Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "These are the models we compared. We also used a Dummy Classifier as baseline."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import  KNeighborsClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import LinearSVC"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T15:57:37.993943Z",
     "end_time": "2023-04-07T15:57:38.031349Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As always, we need to read each .csv file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "emotions = ['love','anger','fear','surprise','joy','sadness']\n",
    "\n",
    "df_love = pd.read_csv('C:/users/kecco/Documenti/Github/DataMining-EmotionDetection/data/Processed/Dataset/StackOverflow/love.csv',sep=';',encoding='iso-8859-1')\n",
    "\n",
    "df_anger = pd.read_csv('C:/users/kecco/Documenti/Github/DataMining-EmotionDetection/data/Processed/Dataset/StackOverflow/anger.csv',sep=';',encoding='iso-8859-1')\n",
    "\n",
    "df_fear = pd.read_csv('C:/users/kecco/Documenti/Github/DataMining-EmotionDetection/data/Processed/Dataset/StackOverflow/fear.csv',sep=';',encoding='iso-8859-1')\n",
    "\n",
    "df_surprise = pd.read_csv('C:/users/kecco/Documenti/Github/DataMining-EmotionDetection/data/Processed/Dataset/StackOverflow/surprise.csv',sep=';',encoding='iso-8859-1')\n",
    "\n",
    "df_joy = pd.read_csv('C:/users/kecco/Documenti/Github/DataMining-EmotionDetection/data/Processed/Dataset/StackOverflow/joy.csv',sep=';',encoding='iso-8859-1')\n",
    "\n",
    "df_sadness = pd.read_csv('C:/users/kecco/Documenti/Github/DataMining-EmotionDetection/data/Processed/Dataset/StackOverflow/sadness.csv',sep=';',encoding='iso-8859-1')\n",
    "\n",
    "df_list = [df_love,df_anger,df_fear,df_surprise,df_joy,df_sadness]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T15:57:40.884467Z",
     "end_time": "2023-04-07T15:57:41.098542Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Word vectors, or word embeddings, are vectors of numbers that provide information about the meaning of a word, as well as its context.\n",
    "\n",
    "spaCy’s small pipeline packages (all packages that end in sm) don’t ship with word vectors, and only include context-sensitive tensors. So in order to use real word vectors, we need to download a larger pipeline package, trained using the word2vec family of algorithms:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-lg==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.5.0/en_core_web_lg-3.5.0-py3-none-any.whl (587.7 MB)\n",
      "     -------------------------------------- 587.7/587.7 MB 2.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in c:\\users\\kecco\\documents\\github\\datamining-emotiondetection\\venv\\lib\\site-packages (from en-core-web-lg==3.5.0) (3.5.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\kecco\\documents\\github\\datamining-emotiondetection\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.7)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\kecco\\documents\\github\\datamining-emotiondetection\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\kecco\\documents\\github\\datamining-emotiondetection\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.4.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\kecco\\documents\\github\\datamining-emotiondetection\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\kecco\\documents\\github\\datamining-emotiondetection\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.10.5)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\kecco\\documents\\github\\datamining-emotiondetection\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kecco\\documents\\github\\datamining-emotiondetection\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\kecco\\documents\\github\\datamining-emotiondetection\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\kecco\\documents\\github\\datamining-emotiondetection\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\kecco\\documents\\github\\datamining-emotiondetection\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\kecco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.27.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\kecco\\documents\\github\\datamining-emotiondetection\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kecco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (21.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\kecco\\documents\\github\\datamining-emotiondetection\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\kecco\\documents\\github\\datamining-emotiondetection\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\kecco\\documents\\github\\datamining-emotiondetection\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\kecco\\documents\\github\\datamining-emotiondetection\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\kecco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.21.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kecco\\documents\\github\\datamining-emotiondetection\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (65.5.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\kecco\\documents\\github\\datamining-emotiondetection\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\kecco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging>=20.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\kecco\\documents\\github\\datamining-emotiondetection\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kecco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\kecco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kecco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kecco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.26.9)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\kecco\\documents\\github\\datamining-emotiondetection\\venv\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\kecco\\documents\\github\\datamining-emotiondetection\\venv\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\kecco\\documents\\github\\datamining-emotiondetection\\venv\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\kecco\\documents\\github\\datamining-emotiondetection\\venv\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kecco\\documents\\github\\datamining-emotiondetection\\venv\\lib\\site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.1.2)\n",
      "\u001B[38;5;2m[+] Download and installation successful\u001B[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#!pip install spacy-transformers\n",
    "# en_core_web_trf\n",
    "\n",
    "!python -m spacy download en_core_web_lg\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T15:57:42.577038Z",
     "end_time": "2023-04-07T15:59:09.539029Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In each dataframe we have same set of sentences, so x will be the same"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       SVG transform on text attribute works excellen...\n",
      "1       Excellent! This is exactly what I needed. Thanks!\n",
      "2       Have added a modern solution as of May 2014 in...\n",
      "3       Have you tried removing 'preload' attribute? (...\n",
      "4       A smarter, entirely C++-way of doing what you ...\n",
      "                              ...                        \n",
      "4795    Yes - that feature is extremely useful for wri...\n",
      "4796    Works great! And you can add \"desc\" after the ...\n",
      "4797    Yeah, I didn't know about the non-greedy thing...\n",
      "4798    Fortunately I'm doing *very* little with Offic...\n",
      "4799    Another very fast approach is the [seek method...\n",
      "Name: Text, Length: 4800, dtype: object\n"
     ]
    }
   ],
   "source": [
    "sentences = df_love['Text']\n",
    "\n",
    "print(sentences)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T15:59:09.558064Z",
     "end_time": "2023-04-07T15:59:09.600281Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We need to create a Transformer class to insert the spacy features in the scikit pipeline in the next phase. This transformer need to have a fit and a transform method, where we apply the preprocessing steps to clean the text, and then we extract comments' vectors."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Spacy packages that come with built-in word vectors make them available as the Token.vector attribute.\n",
    "Doc.vector and Span.vector will default to an average of their token vectors. Vector averaging means that the vector of multiple tokens is insensitive to the order of the words.\n",
    "The vector will be a one-dimensional Numpy array of float numbers and has 300 dimensions. The sentence vector is the same shape as the word vector because it is made up of the average of the word vectors over each word in the sentence."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class WordVectorTransformer(TransformerMixin,BaseEstimator):\n",
    "    def __init__(self, model=\"en_core_web_lg\"):\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        nlp = spacy.load(self.model)\n",
    "\n",
    "        docs = []\n",
    "\n",
    "        for doc in X:\n",
    "\n",
    "            filtered = [token.text for token in nlp(doc) if not token.is_stop  and not token.is_digit and not token.is_punct and not token.is_bracket and not token.like_num and not token.like_url and not token.is_quote]\n",
    "\n",
    "            docs.append(filtered)\n",
    "\n",
    "        final_docs = []\n",
    "\n",
    "        for d in docs:\n",
    "\n",
    "            j = ' '.join(d)\n",
    "            final_docs.append(j)\n",
    "\n",
    "        return np.concatenate([nlp(doc).vector.reshape(1,-1) for doc in final_docs])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T15:59:49.870888Z",
     "end_time": "2023-04-07T15:59:49.881231Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we need to associate some specific sentiment labels (y)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# i indice vettore nomi emozioni\n",
    "\n",
    "def set_labels(df,i):\n",
    "    y = df['label']\n",
    "    y = y.fillna(0)\n",
    "    y = y.map({emotions[i].upper(): 1, 0: 0}).astype(int)\n",
    "    return y\n",
    "\n",
    "x = sentences\n",
    "\n",
    "y = set_labels(df_anger,1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T15:59:53.088786Z",
     "end_time": "2023-04-07T15:59:53.145486Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "SVM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We create a pipeline in wich we have 3 steps:\n",
    "- the WordVectorTransformer class previously created, that will preprocess the text\n",
    "- a SMOTE instance, that will apply a SMOTE algorithm to our data. We tried a RandomUnderSampler but we find SMOTE better.\n",
    "- a LinearSVC instance as classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "steps = [\n",
    "    (\"scaler\", WordVectorTransformer()),\n",
    "    (\"sampler\", SMOTE()),\n",
    "    (\"classification\", LinearSVC(max_iter=10000))\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(steps)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T18:16:19.472900Z",
     "end_time": "2023-04-07T18:16:19.496923Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We also defined a function for printing the classification report. Then, we use cross validation for evaluating. The StratifiedKFold function returns k=5 folds preserving the same percentage of samples for each class."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kecco\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.77      0.84       784\n",
      "           1       0.40      0.66      0.50       176\n",
      "\n",
      "    accuracy                           0.75       960\n",
      "   macro avg       0.65      0.72      0.67       960\n",
      "weighted avg       0.82      0.75      0.78       960\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kecco\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.76      0.83       784\n",
      "           1       0.40      0.72      0.52       176\n",
      "\n",
      "    accuracy                           0.75       960\n",
      "   macro avg       0.66      0.74      0.68       960\n",
      "weighted avg       0.83      0.75      0.78       960\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kecco\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.80      0.85       784\n",
      "           1       0.43      0.65      0.52       176\n",
      "\n",
      "    accuracy                           0.78       960\n",
      "   macro avg       0.67      0.73      0.69       960\n",
      "weighted avg       0.82      0.78      0.79       960\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kecco\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.87       783\n",
      "           1       0.46      0.68      0.55       177\n",
      "\n",
      "    accuracy                           0.79       960\n",
      "   macro avg       0.69      0.75      0.71       960\n",
      "weighted avg       0.83      0.79      0.81       960\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kecco\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.77      0.84       783\n",
      "           1       0.43      0.76      0.54       177\n",
      "\n",
      "    accuracy                           0.77       960\n",
      "   macro avg       0.68      0.76      0.69       960\n",
      "weighted avg       0.84      0.77      0.79       960\n",
      "\n",
      "[0.75416667 0.753125   0.77604167 0.79479167 0.76666667]\n"
     ]
    }
   ],
   "source": [
    "def classification_report_with_accuracy_score(y_test, y_pred):\n",
    "\n",
    "    print(classification_report(y_test, y_pred)) # print classification report\n",
    "    return accuracy_score(y_test, y_pred) # return accuracy score\n",
    "\n",
    "svm_results = cross_val_score(\n",
    "    pipeline,\n",
    "    x,\n",
    "    y,\n",
    "    cv = StratifiedKFold(shuffle=True, random_state=15, n_splits=5),\n",
    "    scoring=make_scorer(classification_report_with_accuracy_score)\n",
    ")\n",
    "\n",
    "print(svm_results)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T18:16:21.922801Z",
     "end_time": "2023-04-07T18:32:11.407762Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "RANDOM FOREST"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.90       784\n",
      "           1       0.53      0.34      0.41       176\n",
      "\n",
      "    accuracy                           0.82       960\n",
      "   macro avg       0.69      0.63      0.65       960\n",
      "weighted avg       0.80      0.82      0.81       960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90       784\n",
      "           1       0.54      0.27      0.36       176\n",
      "\n",
      "    accuracy                           0.82       960\n",
      "   macro avg       0.70      0.61      0.63       960\n",
      "weighted avg       0.80      0.82      0.80       960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.89       784\n",
      "           1       0.47      0.35      0.40       176\n",
      "\n",
      "    accuracy                           0.81       960\n",
      "   macro avg       0.66      0.63      0.64       960\n",
      "weighted avg       0.79      0.81      0.80       960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89       783\n",
      "           1       0.52      0.33      0.40       177\n",
      "\n",
      "    accuracy                           0.82       960\n",
      "   macro avg       0.69      0.63      0.65       960\n",
      "weighted avg       0.80      0.82      0.80       960\n",
      "\n",
      "[0.82291667 0.82395833 0.80729167 0.821875   0.81979167]\n"
     ]
    }
   ],
   "source": [
    "steps = [\n",
    "    (\"scaler\", WordVectorTransformer()),\n",
    "    (\"sampler\", SMOTE()),\n",
    "    (\"classification\", RandomForestClassifier())\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "rf_results = cross_val_score(\n",
    "    pipeline,\n",
    "    x,\n",
    "    y,\n",
    "    cv = StratifiedKFold(shuffle=True, random_state=15, n_splits=5),\n",
    "    scoring=make_scorer(classification_report_with_accuracy_score)\n",
    ")\n",
    "\n",
    "print(rf_results)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T16:53:52.417576Z",
     "end_time": "2023-04-07T17:06:01.773418Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "KNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.41      0.57       784\n",
      "           1       0.26      0.90      0.40       176\n",
      "\n",
      "    accuracy                           0.50       960\n",
      "   macro avg       0.60      0.66      0.49       960\n",
      "weighted avg       0.82      0.50      0.54       960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.34      0.50       784\n",
      "           1       0.24      0.90      0.37       176\n",
      "\n",
      "    accuracy                           0.45       960\n",
      "   macro avg       0.59      0.62      0.44       960\n",
      "weighted avg       0.81      0.45      0.48       960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.39      0.56       784\n",
      "           1       0.25      0.93      0.40       176\n",
      "\n",
      "    accuracy                           0.49       960\n",
      "   macro avg       0.61      0.66      0.48       960\n",
      "weighted avg       0.83      0.49      0.53       960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.38      0.54       783\n",
      "           1       0.25      0.91      0.39       177\n",
      "\n",
      "    accuracy                           0.48       960\n",
      "   macro avg       0.60      0.65      0.47       960\n",
      "weighted avg       0.82      0.48      0.52       960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.41      0.58       783\n",
      "           1       0.26      0.89      0.40       177\n",
      "\n",
      "    accuracy                           0.50       960\n",
      "   macro avg       0.60      0.65      0.49       960\n",
      "weighted avg       0.82      0.50      0.54       960\n",
      "\n",
      "[0.50104167 0.44583333 0.48958333 0.478125   0.50208333]\n"
     ]
    }
   ],
   "source": [
    "steps = [\n",
    "    (\"scaler\", WordVectorTransformer()),\n",
    "    (\"sampler\", SMOTE()),\n",
    "    (\"classification\", KNeighborsClassifier())\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "knn_results = cross_val_score(\n",
    "    pipeline,\n",
    "    x,\n",
    "    y,\n",
    "    cv = StratifiedKFold(shuffle=True, random_state=15, n_splits=5),\n",
    "    scoring=make_scorer(classification_report_with_accuracy_score)\n",
    ")\n",
    "\n",
    "print(knn_results)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T18:33:16.329524Z",
     "end_time": "2023-04-07T18:44:04.080846Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "DUMMY"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kecco\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kecco\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kecco\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90       784\n",
      "           1       0.00      0.00      0.00       176\n",
      "\n",
      "    accuracy                           0.82       960\n",
      "   macro avg       0.41      0.50      0.45       960\n",
      "weighted avg       0.67      0.82      0.73       960\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [31], line 9\u001B[0m\n\u001B[0;32m      1\u001B[0m steps \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m      2\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscaler\u001B[39m\u001B[38;5;124m\"\u001B[39m, WordVectorTransformer()),\n\u001B[0;32m      3\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msampler\u001B[39m\u001B[38;5;124m\"\u001B[39m, SMOTE()),\n\u001B[0;32m      4\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclassification\u001B[39m\u001B[38;5;124m\"\u001B[39m, DummyClassifier())\n\u001B[0;32m      5\u001B[0m ]\n\u001B[0;32m      7\u001B[0m pipeline \u001B[38;5;241m=\u001B[39m Pipeline(steps)\n\u001B[1;32m----> 9\u001B[0m dummy_results \u001B[38;5;241m=\u001B[39m cross_val_score(\n\u001B[0;32m     10\u001B[0m     pipeline,\n\u001B[0;32m     11\u001B[0m     x,\n\u001B[0;32m     12\u001B[0m     y,\n\u001B[0;32m     13\u001B[0m     cv \u001B[38;5;241m=\u001B[39m StratifiedKFold(shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m15\u001B[39m, n_splits\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m),\n\u001B[0;32m     14\u001B[0m     scoring\u001B[38;5;241m=\u001B[39mmake_scorer(classification_report_with_accuracy_score)\n\u001B[0;32m     15\u001B[0m )\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28mprint\u001B[39m(dummy_results)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:509\u001B[0m, in \u001B[0;36mcross_val_score\u001B[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001B[0m\n\u001B[0;32m    506\u001B[0m \u001B[38;5;66;03m# To ensure multimetric format is not supported\u001B[39;00m\n\u001B[0;32m    507\u001B[0m scorer \u001B[38;5;241m=\u001B[39m check_scoring(estimator, scoring\u001B[38;5;241m=\u001B[39mscoring)\n\u001B[1;32m--> 509\u001B[0m cv_results \u001B[38;5;241m=\u001B[39m \u001B[43mcross_validate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    510\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    511\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    512\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    513\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgroups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    514\u001B[0m \u001B[43m    \u001B[49m\u001B[43mscoring\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mscore\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mscorer\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    515\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    516\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    517\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    518\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    519\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpre_dispatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpre_dispatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    520\u001B[0m \u001B[43m    \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    521\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    522\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cv_results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_score\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:267\u001B[0m, in \u001B[0;36mcross_validate\u001B[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001B[0m\n\u001B[0;32m    264\u001B[0m \u001B[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001B[39;00m\n\u001B[0;32m    265\u001B[0m \u001B[38;5;66;03m# independent, and that it is pickle-able.\u001B[39;00m\n\u001B[0;32m    266\u001B[0m parallel \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39mn_jobs, verbose\u001B[38;5;241m=\u001B[39mverbose, pre_dispatch\u001B[38;5;241m=\u001B[39mpre_dispatch)\n\u001B[1;32m--> 267\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    269\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    270\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    271\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    272\u001B[0m \u001B[43m        \u001B[49m\u001B[43mscorers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    273\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    274\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    275\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    276\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    277\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    278\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_train_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_train_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    279\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_times\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    280\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_estimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_estimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    281\u001B[0m \u001B[43m        \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    282\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    283\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    284\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    286\u001B[0m _warn_about_fit_failures(results, error_score)\n\u001B[0;32m    288\u001B[0m \u001B[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001B[39;00m\n\u001B[0;32m    289\u001B[0m \u001B[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001B[39;00m\n\u001B[0;32m    290\u001B[0m \u001B[38;5;66;03m# the correct key.\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\DataMining-EmotionDetection\\venv\\lib\\site-packages\\joblib\\parallel.py:1088\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1085\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_one_batch(iterator):\n\u001B[0;32m   1086\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1088\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdispatch_one_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m   1089\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m   1091\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pre_dispatch \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mall\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   1092\u001B[0m     \u001B[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001B[39;00m\n\u001B[0;32m   1093\u001B[0m     \u001B[38;5;66;03m# No need to wait for async callbacks to trigger to\u001B[39;00m\n\u001B[0;32m   1094\u001B[0m     \u001B[38;5;66;03m# consumption.\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\DataMining-EmotionDetection\\venv\\lib\\site-packages\\joblib\\parallel.py:901\u001B[0m, in \u001B[0;36mParallel.dispatch_one_batch\u001B[1;34m(self, iterator)\u001B[0m\n\u001B[0;32m    899\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    900\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 901\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    902\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\DataMining-EmotionDetection\\venv\\lib\\site-packages\\joblib\\parallel.py:819\u001B[0m, in \u001B[0;36mParallel._dispatch\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    817\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m    818\u001B[0m     job_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs)\n\u001B[1;32m--> 819\u001B[0m     job \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    820\u001B[0m     \u001B[38;5;66;03m# A job can complete so quickly than its callback is\u001B[39;00m\n\u001B[0;32m    821\u001B[0m     \u001B[38;5;66;03m# called before we get here, causing self._jobs to\u001B[39;00m\n\u001B[0;32m    822\u001B[0m     \u001B[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001B[39;00m\n\u001B[0;32m    823\u001B[0m     \u001B[38;5;66;03m# used (rather than .append) in the following line\u001B[39;00m\n\u001B[0;32m    824\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs\u001B[38;5;241m.\u001B[39minsert(job_idx, job)\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\DataMining-EmotionDetection\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001B[0m, in \u001B[0;36mSequentialBackend.apply_async\u001B[1;34m(self, func, callback)\u001B[0m\n\u001B[0;32m    206\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_async\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, callback\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    207\u001B[0m     \u001B[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001B[39;00m\n\u001B[1;32m--> 208\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mImmediateResult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    209\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m callback:\n\u001B[0;32m    210\u001B[0m         callback(result)\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\DataMining-EmotionDetection\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001B[0m, in \u001B[0;36mImmediateResult.__init__\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    594\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch):\n\u001B[0;32m    595\u001B[0m     \u001B[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001B[39;00m\n\u001B[0;32m    596\u001B[0m     \u001B[38;5;66;03m# arguments in memory\u001B[39;00m\n\u001B[1;32m--> 597\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m \u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\DataMining-EmotionDetection\\venv\\lib\\site-packages\\joblib\\parallel.py:288\u001B[0m, in \u001B[0;36mBatchedCalls.__call__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    285\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[0;32m    286\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[0;32m    287\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[1;32m--> 288\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    289\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\DataMining-EmotionDetection\\venv\\lib\\site-packages\\joblib\\parallel.py:288\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    285\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[0;32m    286\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[0;32m    287\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[1;32m--> 288\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    289\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig):\n\u001B[1;32m--> 216\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:702\u001B[0m, in \u001B[0;36m_fit_and_score\u001B[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[0;32m    699\u001B[0m result[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit_error\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    701\u001B[0m fit_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time\n\u001B[1;32m--> 702\u001B[0m test_scores \u001B[38;5;241m=\u001B[39m \u001B[43m_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscorer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merror_score\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    703\u001B[0m score_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time \u001B[38;5;241m-\u001B[39m fit_time\n\u001B[0;32m    704\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m return_train_score:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:761\u001B[0m, in \u001B[0;36m_score\u001B[1;34m(estimator, X_test, y_test, scorer, error_score)\u001B[0m\n\u001B[0;32m    759\u001B[0m         scores \u001B[38;5;241m=\u001B[39m scorer(estimator, X_test)\n\u001B[0;32m    760\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 761\u001B[0m         scores \u001B[38;5;241m=\u001B[39m \u001B[43mscorer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    762\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m    763\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m error_score \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:103\u001B[0m, in \u001B[0;36m_MultimetricScorer.__call__\u001B[1;34m(self, estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m    101\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name, scorer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_scorers\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m    102\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(scorer, _BaseScorer):\n\u001B[1;32m--> 103\u001B[0m         score \u001B[38;5;241m=\u001B[39m scorer\u001B[38;5;241m.\u001B[39m_score(cached_call, estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    104\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    105\u001B[0m         score \u001B[38;5;241m=\u001B[39m scorer(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:258\u001B[0m, in \u001B[0;36m_PredictScorer._score\u001B[1;34m(self, method_caller, estimator, X, y_true, sample_weight)\u001B[0m\n\u001B[0;32m    230\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_score\u001B[39m(\u001B[38;5;28mself\u001B[39m, method_caller, estimator, X, y_true, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    231\u001B[0m     \u001B[38;5;124;03m\"\"\"Evaluate predicted target values for X relative to y_true.\u001B[39;00m\n\u001B[0;32m    232\u001B[0m \n\u001B[0;32m    233\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    255\u001B[0m \u001B[38;5;124;03m        Score function applied to prediction of estimator on X.\u001B[39;00m\n\u001B[0;32m    256\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 258\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m \u001B[43mmethod_caller\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpredict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    259\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    260\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sign \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_score_func(\n\u001B[0;32m    261\u001B[0m             y_true, y_pred, sample_weight\u001B[38;5;241m=\u001B[39msample_weight, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_kwargs\n\u001B[0;32m    262\u001B[0m         )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:68\u001B[0m, in \u001B[0;36m_cached_call\u001B[1;34m(cache, estimator, method, *args, **kwargs)\u001B[0m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;124;03m\"\"\"Call estimator with method and args and kwargs.\"\"\"\u001B[39;00m\n\u001B[0;32m     67\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 68\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(estimator, method)(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     70\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     71\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cache[method]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\metaestimators.py:113\u001B[0m, in \u001B[0;36m_AvailableIfDescriptor.__get__.<locals>.<lambda>\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    110\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m attr_err\n\u001B[0;32m    112\u001B[0m     \u001B[38;5;66;03m# lambda, but not partial, allows help() to work with update_wrapper\u001B[39;00m\n\u001B[1;32m--> 113\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfn(obj, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# noqa\u001B[39;00m\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    116\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfn\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py:469\u001B[0m, in \u001B[0;36mPipeline.predict\u001B[1;34m(self, X, **predict_params)\u001B[0m\n\u001B[0;32m    467\u001B[0m Xt \u001B[38;5;241m=\u001B[39m X\n\u001B[0;32m    468\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _, name, transform \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iter(with_final\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m--> 469\u001B[0m     Xt \u001B[38;5;241m=\u001B[39m \u001B[43mtransform\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mXt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    470\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m][\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mpredict(Xt, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpredict_params)\n",
      "Cell \u001B[1;32mIn [6], line 26\u001B[0m, in \u001B[0;36mWordVectorTransformer.transform\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m     23\u001B[0m     j \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(d)\n\u001B[0;32m     24\u001B[0m     final_docs\u001B[38;5;241m.\u001B[39mappend(j)\n\u001B[1;32m---> 26\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mconcatenate([nlp(doc)\u001B[38;5;241m.\u001B[39mvector\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m final_docs])\n",
      "Cell \u001B[1;32mIn [6], line 26\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     23\u001B[0m     j \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(d)\n\u001B[0;32m     24\u001B[0m     final_docs\u001B[38;5;241m.\u001B[39mappend(j)\n\u001B[1;32m---> 26\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mconcatenate([\u001B[43mnlp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdoc\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mvector\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m final_docs])\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\DataMining-EmotionDetection\\venv\\lib\\site-packages\\spacy\\language.py:1011\u001B[0m, in \u001B[0;36mLanguage.__call__\u001B[1;34m(self, text, disable, component_cfg)\u001B[0m\n\u001B[0;32m   1009\u001B[0m     error_handler \u001B[38;5;241m=\u001B[39m proc\u001B[38;5;241m.\u001B[39mget_error_handler()\n\u001B[0;32m   1010\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1011\u001B[0m     doc \u001B[38;5;241m=\u001B[39m proc(doc, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcomponent_cfg\u001B[38;5;241m.\u001B[39mget(name, {}))  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m   1012\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1013\u001B[0m     \u001B[38;5;66;03m# This typically happens if a component is not initialized\u001B[39;00m\n\u001B[0;32m   1014\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(Errors\u001B[38;5;241m.\u001B[39mE109\u001B[38;5;241m.\u001B[39mformat(name\u001B[38;5;241m=\u001B[39mname)) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\DataMining-EmotionDetection\\venv\\lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:52\u001B[0m, in \u001B[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\DataMining-EmotionDetection\\venv\\lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx:253\u001B[0m, in \u001B[0;36mspacy.pipeline.transition_parser.Parser.predict\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\DataMining-EmotionDetection\\venv\\lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx:274\u001B[0m, in \u001B[0;36mspacy.pipeline.transition_parser.Parser.greedy_parse\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\DataMining-EmotionDetection\\venv\\lib\\site-packages\\thinc\\model.py:315\u001B[0m, in \u001B[0;36mModel.predict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    311\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m OutT:\n\u001B[0;32m    312\u001B[0m     \u001B[38;5;124;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001B[39;00m\n\u001B[0;32m    313\u001B[0m \u001B[38;5;124;03m    only the output, instead of the `(output, callback)` tuple.\u001B[39;00m\n\u001B[0;32m    314\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 315\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\DataMining-EmotionDetection\\venv\\lib\\site-packages\\spacy\\ml\\tb_framework.py:33\u001B[0m, in \u001B[0;36mforward\u001B[1;34m(model, X, is_train)\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(model, X, is_train):\n\u001B[1;32m---> 33\u001B[0m     step_model \u001B[38;5;241m=\u001B[39m \u001B[43mParserStepModel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     34\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     35\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     36\u001B[0m \u001B[43m        \u001B[49m\u001B[43munseen_classes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43munseen_classes\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     37\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     38\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhas_upper\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mhas_upper\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     39\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     41\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m step_model, step_model\u001B[38;5;241m.\u001B[39mfinish_steps\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\DataMining-EmotionDetection\\venv\\lib\\site-packages\\spacy\\ml\\parser_model.pyx:213\u001B[0m, in \u001B[0;36mspacy.ml.parser_model.ParserStepModel.__init__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\DataMining-EmotionDetection\\venv\\lib\\site-packages\\thinc\\model.py:291\u001B[0m, in \u001B[0;36mModel.__call__\u001B[1;34m(self, X, is_train)\u001B[0m\n\u001B[0;32m    288\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[0;32m    289\u001B[0m     \u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[0;32m    290\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 291\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\DataMining-EmotionDetection\\venv\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001B[0m, in \u001B[0;36mforward\u001B[1;34m(model, X, is_train)\u001B[0m\n\u001B[0;32m     53\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[1;32m---> 55\u001B[0m     Y, inc_layer_grad \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mappend(inc_layer_grad)\n\u001B[0;32m     57\u001B[0m     X \u001B[38;5;241m=\u001B[39m Y\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\DataMining-EmotionDetection\\venv\\lib\\site-packages\\thinc\\model.py:291\u001B[0m, in \u001B[0;36mModel.__call__\u001B[1;34m(self, X, is_train)\u001B[0m\n\u001B[0;32m    288\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[0;32m    289\u001B[0m     \u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[0;32m    290\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 291\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\DataMining-EmotionDetection\\venv\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001B[0m, in \u001B[0;36mforward\u001B[1;34m(model, X, is_train)\u001B[0m\n\u001B[0;32m     53\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[1;32m---> 55\u001B[0m     Y, inc_layer_grad \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mappend(inc_layer_grad)\n\u001B[0;32m     57\u001B[0m     X \u001B[38;5;241m=\u001B[39m Y\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\DataMining-EmotionDetection\\venv\\lib\\site-packages\\thinc\\model.py:291\u001B[0m, in \u001B[0;36mModel.__call__\u001B[1;34m(self, X, is_train)\u001B[0m\n\u001B[0;32m    288\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[0;32m    289\u001B[0m     \u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[0;32m    290\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 291\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\DataMining-EmotionDetection\\venv\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001B[0m, in \u001B[0;36mforward\u001B[1;34m(model, X, is_train)\u001B[0m\n\u001B[0;32m     53\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[1;32m---> 55\u001B[0m     Y, inc_layer_grad \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mappend(inc_layer_grad)\n\u001B[0;32m     57\u001B[0m     X \u001B[38;5;241m=\u001B[39m Y\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\DataMining-EmotionDetection\\venv\\lib\\site-packages\\thinc\\model.py:291\u001B[0m, in \u001B[0;36mModel.__call__\u001B[1;34m(self, X, is_train)\u001B[0m\n\u001B[0;32m    288\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[0;32m    289\u001B[0m     \u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[0;32m    290\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 291\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\DataMining-EmotionDetection\\venv\\lib\\site-packages\\thinc\\layers\\concatenate.py:44\u001B[0m, in \u001B[0;36mforward\u001B[1;34m(model, X, is_train)\u001B[0m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(model: Model[InT, OutT], X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[1;32m---> 44\u001B[0m     Ys, callbacks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39m[layer(X, is_train\u001B[38;5;241m=\u001B[39mis_train) \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers])\n\u001B[0;32m     45\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(Ys[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;28mlist\u001B[39m):\n\u001B[0;32m     46\u001B[0m         data_l, backprop \u001B[38;5;241m=\u001B[39m _list_forward(model, X, Ys, callbacks, is_train)\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\DataMining-EmotionDetection\\venv\\lib\\site-packages\\thinc\\layers\\concatenate.py:44\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(model: Model[InT, OutT], X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[1;32m---> 44\u001B[0m     Ys, callbacks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39m[\u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers])\n\u001B[0;32m     45\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(Ys[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;28mlist\u001B[39m):\n\u001B[0;32m     46\u001B[0m         data_l, backprop \u001B[38;5;241m=\u001B[39m _list_forward(model, X, Ys, callbacks, is_train)\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\DataMining-EmotionDetection\\venv\\lib\\site-packages\\thinc\\model.py:291\u001B[0m, in \u001B[0;36mModel.__call__\u001B[1;34m(self, X, is_train)\u001B[0m\n\u001B[0;32m    288\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[0;32m    289\u001B[0m     \u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[0;32m    290\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 291\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\DataMining-EmotionDetection\\venv\\lib\\site-packages\\spacy\\ml\\staticvectors.py:56\u001B[0m, in \u001B[0;36mforward\u001B[1;34m(model, docs, is_train)\u001B[0m\n\u001B[0;32m     54\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(Errors\u001B[38;5;241m.\u001B[39mE896)\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 56\u001B[0m     vectors_data \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgemm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mV\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mW\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrans2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n\u001B[0;32m     58\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(Errors\u001B[38;5;241m.\u001B[39mE896)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "steps = [\n",
    "    (\"scaler\", WordVectorTransformer()),\n",
    "    (\"sampler\", SMOTE()),\n",
    "    (\"classification\", DummyClassifier())\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "dummy_results = cross_val_score(\n",
    "    pipeline,\n",
    "    x,\n",
    "    y,\n",
    "    cv = StratifiedKFold(shuffle=True, random_state=15, n_splits=5),\n",
    "    scoring=make_scorer(classification_report_with_accuracy_score)\n",
    ")\n",
    "\n",
    "print(dummy_results)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's try the other sentiment that was well represented, LOVE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "y = set_labels(df_love,0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T18:48:36.208777Z",
     "end_time": "2023-04-07T18:48:36.232512Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "SVM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kecco\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87       716\n",
      "           1       0.61      0.77      0.68       244\n",
      "\n",
      "    accuracy                           0.81       960\n",
      "   macro avg       0.76      0.80      0.77       960\n",
      "weighted avg       0.83      0.81      0.82       960\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kecco\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87       716\n",
      "           1       0.61      0.76      0.68       244\n",
      "\n",
      "    accuracy                           0.81       960\n",
      "   macro avg       0.76      0.80      0.77       960\n",
      "weighted avg       0.83      0.81      0.82       960\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kecco\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.82      0.86       716\n",
      "           1       0.58      0.72      0.64       244\n",
      "\n",
      "    accuracy                           0.79       960\n",
      "   macro avg       0.74      0.77      0.75       960\n",
      "weighted avg       0.82      0.79      0.80       960\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kecco\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.80      0.85       716\n",
      "           1       0.56      0.73      0.63       244\n",
      "\n",
      "    accuracy                           0.79       960\n",
      "   macro avg       0.73      0.77      0.74       960\n",
      "weighted avg       0.81      0.79      0.79       960\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kecco\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.84      0.87       716\n",
      "           1       0.62      0.75      0.68       244\n",
      "\n",
      "    accuracy                           0.82       960\n",
      "   macro avg       0.76      0.80      0.78       960\n",
      "weighted avg       0.83      0.82      0.82       960\n",
      "\n",
      "[0.81458333 0.81354167 0.79479167 0.78541667 0.81770833]\n"
     ]
    }
   ],
   "source": [
    "steps = [\n",
    "    (\"scaler\", WordVectorTransformer()),\n",
    "    (\"sampler\", SMOTE()),\n",
    "    (\"classification\", LinearSVC(max_iter=10000))\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "svm_results_love = cross_val_score(\n",
    "    pipeline,\n",
    "    x,\n",
    "    y,\n",
    "    cv = StratifiedKFold(shuffle=True, random_state=15, n_splits=5),\n",
    "    scoring=make_scorer(classification_report_with_accuracy_score)\n",
    ")\n",
    "\n",
    "print(svm_results_love)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T18:48:40.056863Z",
     "end_time": "2023-04-07T18:59:39.934874Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "RANDOM FOREST"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89       716\n",
      "           1       0.73      0.57      0.64       244\n",
      "\n",
      "    accuracy                           0.84       960\n",
      "   macro avg       0.80      0.75      0.77       960\n",
      "weighted avg       0.83      0.84      0.83       960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       716\n",
      "           1       0.71      0.57      0.64       244\n",
      "\n",
      "    accuracy                           0.83       960\n",
      "   macro avg       0.79      0.75      0.76       960\n",
      "weighted avg       0.83      0.83      0.83       960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90       716\n",
      "           1       0.75      0.58      0.65       244\n",
      "\n",
      "    accuracy                           0.84       960\n",
      "   macro avg       0.81      0.76      0.77       960\n",
      "weighted avg       0.84      0.84      0.84       960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.90       716\n",
      "           1       0.74      0.56      0.64       244\n",
      "\n",
      "    accuracy                           0.84       960\n",
      "   macro avg       0.80      0.75      0.77       960\n",
      "weighted avg       0.83      0.84      0.83       960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91       716\n",
      "           1       0.78      0.61      0.69       244\n",
      "\n",
      "    accuracy                           0.86       960\n",
      "   macro avg       0.83      0.78      0.80       960\n",
      "weighted avg       0.85      0.86      0.85       960\n",
      "\n",
      "[0.8375     0.83333333 0.84270833 0.8375     0.85729167]\n"
     ]
    }
   ],
   "source": [
    "steps = [\n",
    "    (\"scaler\", WordVectorTransformer()),\n",
    "    (\"sampler\", SMOTE()),\n",
    "    (\"classification\", RandomForestClassifier())\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "rf_results_love = cross_val_score(\n",
    "    pipeline,\n",
    "    x,\n",
    "    y,\n",
    "    cv = StratifiedKFold(shuffle=True, random_state=15, n_splits=5),\n",
    "    scoring=make_scorer(classification_report_with_accuracy_score)\n",
    ")\n",
    "\n",
    "print(rf_results_love)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T19:29:58.047431Z",
     "end_time": "2023-04-07T19:44:56.408730Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With SADNESS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "y = set_labels(df_sadness,5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T19:46:48.786011Z",
     "end_time": "2023-04-07T19:46:48.830489Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "SVM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kecco\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.83      0.89       914\n",
      "           1       0.10      0.37      0.16        46\n",
      "\n",
      "    accuracy                           0.81       960\n",
      "   macro avg       0.53      0.60      0.53       960\n",
      "weighted avg       0.92      0.81      0.86       960\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kecco\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.84      0.90       914\n",
      "           1       0.14      0.54      0.23        46\n",
      "\n",
      "    accuracy                           0.82       960\n",
      "   macro avg       0.56      0.69      0.56       960\n",
      "weighted avg       0.93      0.82      0.87       960\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kecco\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.86      0.91       914\n",
      "           1       0.13      0.39      0.19        46\n",
      "\n",
      "    accuracy                           0.84       960\n",
      "   macro avg       0.55      0.63      0.55       960\n",
      "weighted avg       0.93      0.84      0.88       960\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kecco\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.91       914\n",
      "           1       0.14      0.46      0.21        46\n",
      "\n",
      "    accuracy                           0.84       960\n",
      "   macro avg       0.55      0.66      0.56       960\n",
      "weighted avg       0.93      0.84      0.87       960\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kecco\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.81      0.88       914\n",
      "           1       0.13      0.59      0.22        46\n",
      "\n",
      "    accuracy                           0.79       960\n",
      "   macro avg       0.55      0.70      0.55       960\n",
      "weighted avg       0.93      0.79      0.85       960\n",
      "\n",
      "[0.81145833 0.82291667 0.840625   0.83541667 0.79479167]\n"
     ]
    }
   ],
   "source": [
    "steps = [\n",
    "    (\"scaler\", WordVectorTransformer()),\n",
    "    (\"sampler\", SMOTE()),\n",
    "    (\"classification\", LinearSVC(max_iter=10000))\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "svm_results_sadness = cross_val_score(\n",
    "    pipeline,\n",
    "    x,\n",
    "    y,\n",
    "    cv = StratifiedKFold(shuffle=True, random_state=15, n_splits=5),\n",
    "    scoring=make_scorer(classification_report_with_accuracy_score)\n",
    ")\n",
    "\n",
    "print(svm_results_sadness)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T19:46:49.874954Z",
     "end_time": "2023-04-07T20:06:36.272770Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "RANDOM FOREST"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       914\n",
      "           1       0.22      0.09      0.12        46\n",
      "\n",
      "    accuracy                           0.94       960\n",
      "   macro avg       0.59      0.54      0.55       960\n",
      "weighted avg       0.92      0.94      0.93       960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98       914\n",
      "           1       0.50      0.20      0.28        46\n",
      "\n",
      "    accuracy                           0.95       960\n",
      "   macro avg       0.73      0.59      0.63       960\n",
      "weighted avg       0.94      0.95      0.94       960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       914\n",
      "           1       0.37      0.15      0.22        46\n",
      "\n",
      "    accuracy                           0.95       960\n",
      "   macro avg       0.66      0.57      0.59       960\n",
      "weighted avg       0.93      0.95      0.94       960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       914\n",
      "           1       0.36      0.17      0.24        46\n",
      "\n",
      "    accuracy                           0.95       960\n",
      "   macro avg       0.66      0.58      0.60       960\n",
      "weighted avg       0.93      0.95      0.94       960\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       914\n",
      "           1       0.39      0.15      0.22        46\n",
      "\n",
      "    accuracy                           0.95       960\n",
      "   macro avg       0.67      0.57      0.60       960\n",
      "weighted avg       0.93      0.95      0.94       960\n",
      "\n",
      "[0.94166667 0.95208333 0.946875   0.94583333 0.94791667]\n"
     ]
    }
   ],
   "source": [
    "steps = [\n",
    "    (\"scaler\", WordVectorTransformer()),\n",
    "    (\"sampler\", SMOTE()),\n",
    "    (\"classification\", RandomForestClassifier())\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "rf_results_sadness = cross_val_score(\n",
    "    pipeline,\n",
    "    x,\n",
    "    y,\n",
    "    cv = StratifiedKFold(shuffle=True, random_state=15, n_splits=5),\n",
    "    scoring=make_scorer(classification_report_with_accuracy_score)\n",
    ")\n",
    "\n",
    "print(rf_results_sadness)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T20:16:29.334929Z",
     "end_time": "2023-04-07T20:26:07.810209Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**CONCLUSIONS**\n",
    "\n",
    "For our study case, we think it's important to consider the single precision and recall score for each class, more than the single accuracy value, thus we used classification reports to evaluate each run of cross validation. We could use macro averages for comparing models.\n",
    "Generally, the SVM perform better. The Random Forest sometimes has good scores too and KNN does not perform well as the previous ones."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
